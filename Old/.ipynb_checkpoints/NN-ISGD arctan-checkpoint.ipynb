{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import cubic_root_closest_to_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n =  2  # dimension of input\n",
    "m =  3  # dimension of output\n",
    "batch =  4  # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_logit(input, weight, bias=None):\n",
    "    \"\"\"\n",
    "    Calculate logit = input.mm(weight.t()) + bias\n",
    "\n",
    "    Args:\n",
    "        input:  [1 x n]         Input vector\n",
    "        weight:  [m x n]        Weight matrix\n",
    "        bias:  [m]              Bias vector\n",
    "\n",
    "    Returns:\n",
    "        logit: [1 x n]          Logit = input.mm(weight.t()) + bias\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    logit = input.mm(weight.t())\n",
    "    if bias is not None:\n",
    "        logit += bias.unsqueeze(0).expand_as(logit)\n",
    "\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def esgd_arctan(grad_output, input, weight, bias, output):\n",
    "\n",
    "    grad_output_scaled = grad_output / (1 + logit ** 2)  # [1 x m]\n",
    "    grad_input = grad_output_scaled.mm(weight)  # [1 x n]\n",
    "    grad_weight = grad_output_scaled.t().mm(input)  # [m x n]\n",
    "    grad_bias = grad_output_scaled.sum(0).squeeze(0)  # [m]\n",
    "\n",
    "    return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New ISGD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve(coeff):\n",
    "    a, b, c, d = coeff\n",
    "    if (a == 0 and b == 0):  # Case for handling Liner Equation\n",
    "        return np.array([(-d * 1.0) / c])  # Returning linear root as numpy array.\n",
    "\n",
    "    elif (a == 0):  # Case for handling Quadratic Equations\n",
    "\n",
    "        D = c * c - 4.0 * b * d  # Helper Temporary Variable\n",
    "        if D >= 0:\n",
    "            D = math.sqrt(D)\n",
    "            x1 = (-c + D) / (2.0 * b)\n",
    "            x2 = (-c - D) / (2.0 * b)\n",
    "        else:\n",
    "            D = math.sqrt(-D)\n",
    "            x1 = (-c + D * 1j) / (2.0 * b)\n",
    "            x2 = (-c - D * 1j) / (2.0 * b)\n",
    "\n",
    "        return np.array([x1, x2])  # Returning Quadratic Roots as numpy array.\n",
    "\n",
    "    f = findF(a, b, c)  # Helper Temporary Variable\n",
    "    g = findG(a, b, c, d)  # Helper Temporary Variable\n",
    "    h = findH(g, f)  # Helper Temporary Variable\n",
    "\n",
    "    if f == 0 and g == 0 and h == 0:  # All 3 Roots are Real and Equal\n",
    "        if (d / a) >= 0:\n",
    "            x = (d / (1.0 * a)) ** (1 / 3.0) * -1\n",
    "        else:\n",
    "            x = (-d / (1.0 * a)) ** (1 / 3.0)\n",
    "        return np.array([x, x, x])  # Returning Equal Roots as numpy array.\n",
    "\n",
    "    elif h <= 0:  # All 3 roots are Real\n",
    "\n",
    "        i = math.sqrt(((g ** 2.0) / 4.0) - h)  # Helper Temporary Variable\n",
    "        j = i ** (1 / 3.0)  # Helper Temporary Variable\n",
    "        k = math.acos(-(g / (2 * i)))  # Helper Temporary Variable\n",
    "        L = j * -1  # Helper Temporary Variable\n",
    "        M = math.cos(k / 3.0)  # Helper Temporary Variable\n",
    "        N = math.sqrt(3) * math.sin(k / 3.0)  # Helper Temporary Variable\n",
    "        P = (b / (3.0 * a)) * -1  # Helper Temporary Variable\n",
    "\n",
    "        x1 = 2 * j * math.cos(k / 3.0) - (b / (3.0 * a))\n",
    "        x2 = L * (M + N) + P\n",
    "        x3 = L * (M - N) + P\n",
    "\n",
    "        return np.array([x1, x2, x3])  # Returning Real Roots as numpy array.\n",
    "\n",
    "    elif h > 0:  # One Real Root and two Complex Roots\n",
    "        R = -(g / 2.0) + math.sqrt(h)  # Helper Temporary Variable\n",
    "        if R >= 0:\n",
    "            S = R ** (1 / 3.0)  # Helper Temporary Variable\n",
    "        else:\n",
    "            S = (-R) ** (1 / 3.0) * -1  # Helper Temporary Variable\n",
    "        T = -(g / 2.0) - math.sqrt(h)\n",
    "        if T >= 0:\n",
    "            U = (T ** (1 / 3.0))  # Helper Temporary Variable\n",
    "        else:\n",
    "            U = ((-T) ** (1 / 3.0)) * -1  # Helper Temporary Variable\n",
    "\n",
    "        x1 = (S + U) - (b / (3.0 * a))\n",
    "        x2 = -(S + U) / 2 - (b / (3.0 * a)) + (S - U) * math.sqrt(3) * 0.5j\n",
    "        x3 = -(S + U) / 2 - (b / (3.0 * a)) - (S - U) * math.sqrt(3) * 0.5j\n",
    "\n",
    "        return np.array([x1, x2, x3])  # Returning One Real Root and two Complex Roots as numpy array.\n",
    "\n",
    "\n",
    "# Helper function to return float value of f.\n",
    "def findF(a, b, c):\n",
    "    return ((3.0 * c / a) - ((b ** 2.0) / (a ** 2.0))) / 3.0\n",
    "\n",
    "\n",
    "# Helper function to return float value of g.\n",
    "def findG(a, b, c, d):\n",
    "    return (((2.0 * (b ** 3.0)) / (a ** 3.0)) - ((9.0 * b * c) / (a ** 2.0)) + (27.0 * d / a)) / 27.0\n",
    "\n",
    "\n",
    "# Helper function to return float value of h.\n",
    "def findH(g, f):\n",
    "    return ((g ** 2.0) / 4.0 + (f ** 3.0) / 27.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_root_closest_to_zero(coeff):\n",
    "    \"\"\"\n",
    "    Given a list of polynomial coefficients,\n",
    "    return the real root that is closest to zero\n",
    "\n",
    "    Args:\n",
    "        coeff:  List of polynomial coefficients\n",
    "\n",
    "    Returns:\n",
    "        root_closest_to_zero:   Root that is closest to zero\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate all (complex) roots\n",
    "    roots = solve(coeff)  #\n",
    "\n",
    "    # Extract real roots\n",
    "    # Note cannot use root.imag == 0 since numpy sometimes has a tiny imaginary component for real roots\n",
    "    # See: https://stackoverflow.com/questions/28081247/print-real-roots-only-in-numpy\n",
    "    real_roots = (root.real for root in roots if abs(root.imag) < 1e-10)\n",
    "\n",
    "    # Extract the real root that is closest to zero\n",
    "    root = reduce((lambda x, y: x if (abs(x) < abs(y)) else y), real_roots)\n",
    "\n",
    "    return root.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isgd_numpy_arctan(input, weight, bias, output, logit, grad_output):\n",
    "    \n",
    "    # Hyperparameters\n",
    "    lr = 0.000001\n",
    "    mu = 0.0\n",
    "\n",
    "    # ISGD constants\n",
    "    b = grad_output / (1 + lr * mu)  # [b x m]\n",
    "    c = logit / (1.0 + lr * mu)  # [b x m]\n",
    "    z_norm_squared_mat = (torch.norm(input, p=2, dim=1) ** 2 + 1.0).unsqueeze(1).expand_as(c)  # [b x m]\n",
    "\n",
    "    # Coefficients of cubic equation for each power:\n",
    "    # a3*u**3 + a2*u**2 + a1*u + a0 = 0\n",
    "    a3 = ((lr * z_norm_squared_mat) ** 2)  # [b x m]\n",
    "    a2 = (-2 * lr * c * z_norm_squared_mat)  # [b x m]\n",
    "    a1 = (1 + c ** 2)  # [b x m]\n",
    "    a0 = (- b)  # [b x m]\n",
    "\n",
    "    # Coefficients as one big numpy matrix\n",
    "    coeff = torch.stack((a3, a2, a1, a0)).numpy()  # [4 x b x m]\n",
    "\n",
    "    # Calculate roots of cubic that are real and closest to zero\n",
    "#     roots = np.apply_along_axis(real_root_closest_to_zero, 0, coeff)  # [b x m] # Real root closest to zero\n",
    "    roots = cubic_root_closest_to_0.get_roots(coeff)\n",
    "    u = torch.from_numpy(roots)  # [b x m]\n",
    "\n",
    "    # Calculate input gradient\n",
    "    grad_output_scaled = grad_output / (1 + logit ** 2)  # [b x m]\n",
    "    grad_input = grad_output_scaled.mm(weight)  # [b x n]\n",
    "\n",
    "    # Calculate grad_weight, grad_bias\n",
    "    grad_weight = weight * mu / (1.0 + lr * mu) + u.t().mm(input)  # [m x n]\n",
    "    grad_bias = bias * mu / (1.0 + lr * mu) + u.t().sum(1)  # [m]\n",
    "    \n",
    "    return grad_input, grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the differences between ESGD, ISGD old and ISGD_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference between ESGD and ISGD new\n",
      "[\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 4x2]\n",
      ", \n",
      "1.00000e-06 *\n",
      " -0.2682 -0.1490\n",
      " -0.0298  0.1788\n",
      "  3.0994 -2.8610\n",
      "[torch.FloatTensor of size 3x2]\n",
      ", \n",
      "1.00000e-06 *\n",
      "  0.5662\n",
      " -0.2384\n",
      " -2.8610\n",
      "[torch.FloatTensor of size 3]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Random data\n",
    "grad_output = torch.randn(batch, m)     # [b x m]\n",
    "input = torch.randn(batch, n)           # [b x n]\n",
    "weight = torch.randn(m, n)          # [m x n]\n",
    "bias = torch.randn(m,)              # [m]\n",
    "\n",
    "# Forward propagation\n",
    "# Calculate logit [1 x m], where logit = input.mm(weight.t()) + bias\n",
    "logit = calc_logit(input, weight, bias)\n",
    "\n",
    "# Non-linear activation function\n",
    "output = torch.atan(logit)  # [1 x m]\n",
    "\n",
    "# Calculate gradients\n",
    "esgd_grads = esgd_arctan(grad_output, input, weight, bias, output)\n",
    "isgd_new_grads = isgd_numpy_arctan(input, weight, bias, output, logit, grad_output)\n",
    "\n",
    "print('\\nDifference between ESGD and ISGD new')\n",
    "print([(x-y) for x,y in zip(isgd_new_grads, esgd_grads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-02 *\n",
      " -0.1765  0.0747  3.4345\n",
      " -0.0036  0.0032 -0.8608\n",
      " -0.0004  0.0329  0.0028\n",
      " -0.0029  0.1258 -0.0009\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "\n",
      "1.00000e-07 *\n",
      "  0.2980  0.0000  1.1921\n",
      "  0.0373  0.0373  0.0000\n",
      "  0.0000  0.0000 -0.0373\n",
      "  0.0373 -0.1490 -0.0745\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test how accurate the update is in terms of the equation it is supposed to solve\n",
    "\n",
    "def u_diff(grad_output, c, lr, z_norm_squared, u):\n",
    "    return u - grad_output / (1.0 + (c - lr * torch.mul(z_norm_squared, u.t()).t()) ** 2) / (1.0 + lr * mu)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.01\n",
    "mu = 0.0\n",
    "\n",
    "# ISGD constants\n",
    "b = grad_output / (1 + lr * mu)  # [b x m]\n",
    "c = logit / (1.0 + lr * mu)  # [b x m]\n",
    "z_norm_squared_mat = (torch.norm(input, p=2, dim=1) ** 2 + 1.0).unsqueeze(1).expand_as(c)  # [b x m]\n",
    "z_norm_squared = torch.norm(input, p=2, dim=1) ** 2 + 1.0\n",
    "\n",
    "# Coefficients of cubic equation for each power:\n",
    "# a3*u**3 + a2*u**2 + a1*u + a0 = 0\n",
    "a3 = ((lr * z_norm_squared_mat) ** 2)  # [b x m]\n",
    "a2 = (-2 * lr * c * z_norm_squared_mat)  # [b x m]\n",
    "a1 = (1 + c ** 2)  # [b x m]\n",
    "a0 = (- b)  # [b x m]\n",
    "\n",
    "# Coefficients as one big numpy matrix\n",
    "coeff = torch.stack((a3, a2, a1, a0)).numpy()  # [4 x b x m]\n",
    "\n",
    "# Calculate roots of cubic that are real and closest to zero\n",
    "roots = np.apply_along_axis(real_root_closest_to_zero, 0, coeff)  # [b x m] # Real root closest to zero\n",
    "u = torch.from_numpy(roots)  # [b x m]\n",
    "\n",
    "u_esgd = grad_output / (1 + logit ** 2)\n",
    "\n",
    "print(u_diff(grad_output, c, lr, z_norm_squared, u_esgd))\n",
    "print(u_diff(grad_output, c, lr, z_norm_squared, u))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
