{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdditionDataset(Dataset):\n",
    "    \"\"\"Addition dataset as introduced in the original LSTM paper.\n",
    "    This implementation is from p.11 of 'On the difficulty of training recurrent neural networks' \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_length, len_sequence):\n",
    "        self.dataset_length = dataset_length  # This is what is returned by len(), see def __len__(self) below\n",
    "        self.t = len_sequence  # Length of sequence\n",
    "        # Check that sequence length is at least 10\n",
    "        # If not, there is no randomness in the position of the first number to be added\n",
    "        assert(self.t > 10), 'Sequence length must be at least 10'\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, dummy_index):\n",
    "        # The dummy index is required for the dataloader to work,\n",
    "        # but since we are sampling data randomly it has no effect\n",
    "\n",
    "        # Sample the length of the sequence and positions of numbers to add\n",
    "        t_dash = np.random.randint(self.t, int(self.t * 11.0 / 10.0) )  # Length of the sequence\n",
    "        t_1 = np.random.randint(0, int(t_dash / 10.0))  # Indicator of position of first number to add\n",
    "        t_2 = np.random.randint(int(t_dash / 10.0), int(t_dash / 2.0))  # Indicator of position of second number to add\n",
    "\n",
    "        # We generate random numbers uniformly sampled from [0,1]\n",
    "        # as depicted in Figure 2 of\n",
    "        # \"Learning Recurrent Neural Networks with Hessian-Free Optimization\"\n",
    "        # Details of how to sample the numbers was not given in\n",
    "        # \"On the difficulty of training recurrent neural networks\"\n",
    "        sequence = torch.zeros((2, t_dash))  # Initialize empty sequence\n",
    "        sequence[0, :] = torch.rand((1, t_dash))  # Make first row random numbers\n",
    "        \n",
    "        # Set second row to indicate which numbers to add\n",
    "        sequence[1, t_1] = 1.0 \n",
    "        sequence[1, t_2] = 1.0  \n",
    "\n",
    "        # Calculate target\n",
    "        target = sequence[0, t_1] + sequence[0, t_2]\n",
    "        \n",
    "        # Collect sequence and target into a sample\n",
    "        sample = {'sequence': sequence, 'target': target}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addition_problem(train_dataset_length, test_data_length, len_sequence, batch_size=4, num_workers=4):\n",
    "    \"\"\"This is the addition problem\n",
    "\n",
    "    Args:\n",
    "        T: Sequence length\n",
    "\n",
    "    Returns:\n",
    "        train_loader    Loads training data\n",
    "        test_loader     Loads test data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = DataLoader(AdditionDataset(train_dataset_length, len_sequence),\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "    test_loader = DataLoader(AdditionDataset(test_data_length, len_sequence),\n",
    "                             batch_size=batch_size,\n",
    "                             num_workers=num_workers)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = AdditionDataset(dataset_length=8, len_sequence=11)\n",
    "train_loader, test_loader = addition_problem(train_dataset_length=8, test_data_length=9, len_sequence=11, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.8043  0.3458  0.6361  0.3467  0.9410  0.5093  0.1975  0.0848  0.5405\n",
      "  1.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.8104  0.1169\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 1.1501\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "1\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.8069  0.3209  0.4774  0.6750  0.0925  0.2210  0.9256  0.6101  0.5587\n",
      "  1.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.9583  0.7564\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 1.1278\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "2\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.3990  0.8373  0.1908  0.8315  0.5879  0.8295  0.5340  0.8592  0.8446\n",
      "  1.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.7993  0.9168\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 1.2364\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "3\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0085  0.9168  0.0017  0.0158  0.2707  0.5774  0.3935  0.0833  0.7707\n",
      "  1.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.3280  0.6825\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 0.9254\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "4\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.0976  0.4726  0.8456  0.3162  0.3340  0.7380  0.5640  0.7416  0.8733\n",
      "  1.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.9549  0.7247\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 0.9432\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "5\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.4787  0.3694  0.2130  0.5352  0.8967  0.1055  0.6804  0.7449  0.7956\n",
      "  1.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.4513  0.2569\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 0.6917\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "6\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.4464  0.1870  0.2303  0.8121  0.8587  0.1555  0.1892  0.0338  0.5500\n",
      "  1.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.9467  0.6547\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 1.2585\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "7\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.9420  0.2336  0.9945  0.0073  0.7451  0.3971  0.7212  0.8691  0.7072\n",
      "  1.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.9780  0.6631\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 1.9365\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n",
      "8\n",
      "{'sequence': \n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.5630  0.0173  0.7611  0.3405  0.4967  0.8647  0.0702  0.6493  0.8731\n",
      "  1.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 9 to 10 \n",
      "   0.8672  0.7849\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 1x2x11]\n",
      ", 'target': \n",
      " 0.9035\n",
      "[torch.DoubleTensor of size 1]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(test_loader):\n",
    "    print(i_batch)\n",
    "    print(sample_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden))\n",
    "        hidden = self.i2h(combined)\n",
    "        hidden = nn.functional.sigmoid(hidden)\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 10\n",
    "rnn = RNN(2, n_hidden, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.1429\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5770\n",
      " 0.4841\n",
      " 0.6535\n",
      " 0.3875\n",
      " 0.5885\n",
      " 0.5603\n",
      " 0.4657\n",
      " 0.3724\n",
      " 0.4168\n",
      " 0.6209\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[0]\n",
    "input = Variable(sample['sequence'][:,0]) # Variable(torch.rand(2))\n",
    "hidden = Variable(torch.zeros(n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input, hidden)\n",
    "print(output)\n",
    "print(next_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.train()\n",
    "for epoch in range(1):\n",
    "    for i_batch, sample_batched in enumerate(test_loader):\n",
    "        print(i_batch)\n",
    "        print(sample_batched)\n",
    "        \n",
    "        sequence = Variable(sample['sequence'])\n",
    "        target = Variable(torch.Tensor([sample['target']]))\n",
    "\n",
    "#         hidden = rnn.initHidden()\n",
    "#         rnn.zero_grad()\n",
    "\n",
    "#         for i in range(sequence.size()[1]):\n",
    "#             input = sequence[:,i]\n",
    "#             output, hidden = rnn(input, hidden)\n",
    "\n",
    "#         loss = nn.MSELoss()(output, target)\n",
    "# #         if i_batch == 0:\n",
    "# #             print(loss)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence:  Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.8030  0.2471  0.0761  0.3242  0.9985  0.7212  0.0496  0.3132  0.2303  0.5832\n",
      " 1.0000  1.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "Columns 10 to 10 \n",
      " 0.5846\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 2x11]\n",
      "\n",
      "target:  1.050081491470337\n",
      "output:  1.544363260269165\n"
     ]
    }
   ],
   "source": [
    "rnn.eval()\n",
    "sample = train_data[0]\n",
    "sequence = Variable(sample['sequence'], requires_grad=False)\n",
    "target = Variable(torch.Tensor([sample['target']]), requires_grad=False)\n",
    "hidden = rnn.initHidden()\n",
    "for i in range(sequence.size()[1]):\n",
    "    input = sequence[:,i]\n",
    "    output, hidden = rnn(input, hidden)\n",
    "    \n",
    "print('sequence: ', sequence)\n",
    "print('target: ', float(target))\n",
    "print('output: ', float(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
